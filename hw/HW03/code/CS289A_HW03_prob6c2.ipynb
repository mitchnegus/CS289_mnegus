{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load modules to be used in the execution of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import HW03_utils as ut\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_images(image_vectors):\n",
    "# Function to normalize pixel contrast of images\n",
    "\n",
    "        magnitudes = np.linalg.norm(image_vectors,axis=1)\n",
    "        normalized_ims = image_vectors/magnitudes[:,None]\n",
    "        return normalized_ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_bounds(classid,labels):\n",
    "# Function to extract index bounds of the specified class from the dataset\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == classid:\n",
    "            startindex = i\n",
    "            break\n",
    "    stopindex = len(labels)\n",
    "    for i in range(i,len(labels)):\n",
    "        if labels[i] != classid:\n",
    "            stopindex = i\n",
    "            break\n",
    "    \n",
    "    return startindex,stopindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_from_data(classid,data,labels):\n",
    "# Find the start (inclusive) and end (exclusive) of a class within the data, then separate and return the class\n",
    "\n",
    "    startindex,stopindex = get_class_bounds(classid,labels)\n",
    "    \n",
    "    # Separate the specified class\n",
    "    class_data = data[startindex:stopindex]\n",
    "            \n",
    "    return class_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_of_class(classid,data,labels):\n",
    "# Calculate the mean value when the class is fit to a normal distribution\n",
    "    \n",
    "    class_data = get_class_from_data(classid,data,labels)   \n",
    "    # Calculate the mean of the class data\n",
    "    class_mu = np.mean(class_data,axis=0)\n",
    "    \n",
    "    return class_mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cov_of_class(classid,data,labels):\n",
    "# Calcualte the covariance matrix when the class is fit to a normal distribution\n",
    "\n",
    "    class_data = get_class_from_data(classid,data,labels)\n",
    "    # Calculate the covariance matrix from the class data\n",
    "    class_Sigma = np.cov(class_data,rowvar=False)\n",
    "    \n",
    "    return class_Sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Prior(classid,data_labels):\n",
    "        \n",
    "    # Calculate the prior probability\n",
    "    startindex,stopindex = get_class_bounds(classid,data_labels)\n",
    "    nPoints = stopindex-startindex\n",
    "    pi_i = nPoints/len(data_labels)\n",
    "        \n",
    "    return pi_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def QDF_solve(X,muC,SigmaC,piC=0.1):\n",
    "# Function to solve the linear discriminant function for class C (will compute LDF for 1 variable but for all data points)\n",
    "    \n",
    "    QDFs_C = np.zeros(len(X))\n",
    "    invSigmaC = np.linalg.pinv(SigmaC)\n",
    "    detSigmaC = np.linalg.det(SigmaC)\n",
    "    print('det ',detSigmaC)\n",
    "    lndetSigmaC = np.log(detSigmaC)\n",
    "    lnpiC = math.log(piC)\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        QDFs_C[i] = -0.5*np.dot(np.dot((x-muC),invSigmaC),(x-muC))-0.5*lndetSigmaC + lnpiC\n",
    "    \n",
    "    return QDFs_C\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maximize_QDFs(quad_disc_fns):\n",
    "    max_QDF_indices = np.empty(len(quad_disc_fns))\n",
    "    for i in range(len(max_QDF_indices)):\n",
    "        max_QDF_indices[i] = np.argmax(quad_disc_fns[i])\n",
    "    \n",
    "    return max_QDF_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CS_DIR = r\"/Users/mitch/Documents/Cal/2 - 2017 Spring/COMPSCI 289A - Intro to Machine Learning/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "data_array = ut.loaddata(\"hw3_mnist_dist/hw3_mnist_dist/train.mat\",CS_DIR+r\"HW03/Data\",\"trainX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle data and set aside validation set\n",
    "np.random.shuffle(data_array)\n",
    "\n",
    "trainarray = data_array[:-10000]\n",
    "valarray = data_array[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findRedundants(sym_matrix):\n",
    "# Take a symmetric matrix and find rows/columns that are redundant\n",
    "\n",
    "    red_rows = []\n",
    "    for i in range(len(sym_matrix)):\n",
    "        if not np.any(sym_matrix[i]):\n",
    "            red_rows.append(i)\n",
    "        \n",
    "    return red_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeRedundants(matrix,red_vecs_inds):\n",
    "# Eliminate redundant vectors from a matrix, or elements from \n",
    "# a vector corresponding to redundant rows/columns in a matrix\n",
    "    \n",
    "    newlen = len(matrix)-len(red_vecs_inds)\n",
    "    if len(np.shape(matrix))==2:\n",
    "        newmatrix = np.empty((newlen,newlen))\n",
    "        I = 0\n",
    "        for i in range(len(matrix)):\n",
    "            if i in red_vecs_inds:\n",
    "                continue\n",
    "            J = 0\n",
    "            for j in range(len(matrix)):\n",
    "                if j in red_vecs_inds:\n",
    "                    continue\n",
    "                newmatrix[I,J] = matrix[i,j]\n",
    "                J += 1\n",
    "            I += 1\n",
    "\n",
    "        return newmatrix\n",
    "    \n",
    "    if len(np.shape(matrix))==1:\n",
    "        newvector = np.empty(newlen)\n",
    "        I = 0\n",
    "        for i in range(len(matrix)):\n",
    "            if i in red_vecs_inds:\n",
    "                continue\n",
    "            newvector[I] = matrix[i]\n",
    "            I+=1\n",
    "        \n",
    "        return newvector\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(traindata,trainlabels,valdata,vallabels):\n",
    "# Main block of code\n",
    "        \n",
    "    quad_disc_fns = np.empty((len(valdata),10))\n",
    "    for i in range(10):\n",
    "        muC = mean_of_class(i,traindata,trainlabels)\n",
    "        SigmaC = cov_of_class(i,traindata,trainlabels)\n",
    "        sigvals = []\n",
    "        for u in SigmaC:\n",
    "            for v in u:\n",
    "                if v!= 0:\n",
    "                    sigvals.append(v)\n",
    "        print(sigvals)\n",
    "        piC = Prior(i,trainlabels)\n",
    "        \n",
    "        RedVarInds = findRedundants(SigmaC)\n",
    "        newmuC = removeRedundants(muC,RedVarInds)\n",
    "        newSigmaC = removeRedundants(SigmaC,RedVarInds)\n",
    "        print(np.shape(newSigmaC))\n",
    "        newvaldata = np.empty((len(valdata),len(valdata[0])-len(RedVarInds)))\n",
    "        for datapointi in range(len(valdata)):\n",
    "            newvaldata[datapointi] = removeRedundants(valdata[datapointi],RedVarInds)\n",
    "\n",
    "        quad_disc_fns[:,i] = QDF_solve(newvaldata,newmuC,newSigmaC,piC)\n",
    "\n",
    "        digitPicks = maximize_QDFs(quad_disc_fns)\n",
    "        \n",
    "    count, total = 0,0\n",
    "    for i in range(len(digitPicks)):\n",
    "        if digitPicks[i] == vallabels[i]:\n",
    "            count += 1\n",
    "        total += 1\n",
    "        \n",
    "    # VERBOSE COMMANDS FOR WATCHING PROGRESS [OPTIONAL]\n",
    "    #    if total%200 == 0:\n",
    "    #        print(total,'points evaluated; current score =',count/total)\n",
    "    print(count,total)\n",
    "    score = count/total\n",
    "\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organize array by digit\n",
    "trainarray_byclass = trainarray[trainarray[:,-1].argsort()]\n",
    "valarray_byclass = valarray[valarray[:,-1].argsort()]\n",
    "\n",
    "train_data = trainarray_byclass[:,:-1]\n",
    "train_labels = trainarray_byclass[:,-1]\n",
    "\n",
    "val_data = valarray_byclass[:,:-1]\n",
    "val_labels = valarray_byclass[:,-1]\n",
    "\n",
    "normalized_traindata = normalize_images(train_data)\n",
    "normalized_valdata = normalize_images(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = [100,200,500,1000,2000,5000,10000,30000,50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train on subsets of full training data set\n",
    "scores = []\n",
    "for number in samples:\n",
    "    trainarraysubset = trainarray[:number]\n",
    "    \n",
    "    # Organize array by digit\n",
    "    trainarray_byclass = trainarraysubset[trainarraysubset[:,-1].argsort()]\n",
    "    valarray_byclass = valarray[valarray[:,-1].argsort()]\n",
    "    \n",
    "    # Separate data and labels\n",
    "    train_data = trainarray_byclass[:,:-1]\n",
    "    train_labels = trainarray_byclass[:,-1]\n",
    "    val_data = valarray_byclass[:,:-1]\n",
    "    val_labels = valarray_byclass[:,-1]\n",
    "    \n",
    "    # Normalize training and validation data\n",
    "    normalized_train_data = normalize_images(train_data)\n",
    "    normalized_val_data = normalize_images(val_data)\n",
    "    \n",
    "    print(number,\"training samples: \")\n",
    "    score = main(normalized_train_data,train_labels,normalized_val_data,val_labels)\n",
    "    scores.append(score)\n",
    "    print(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = np.ones(len(scores))-np.array(scores)\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.semilogx(samples,error)\n",
    "plt.xlabel(\"# Training Points\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.savefig(\"LDA_errors.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
