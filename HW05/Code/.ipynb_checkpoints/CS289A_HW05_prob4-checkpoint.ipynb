{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW05 - Problem 4\n",
    "==============\n",
    "Performance evaluation. For each of the 3 datasets, train a decision tree and random forest and report your training and validation accuracies. You should be reporting 12 numbers (3 datasets × 2 classifiers × 2 data splits).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program overhead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import decisiontree as dt\n",
    "import HW05_utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the base directory for this homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"/Users/mitch/Documents/Cal/2_2017_Spring/COMPSCI 289A - Intro to Machine Learning/HW05/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a size for the validation set as a fraction of the total training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valfrac = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPAM\n",
    "---------------------------\n",
    "Calculate decision tree and random forest training/validation accuracies for the spam dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing data, shuffling, and separating into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "SPAM_PATH = \"Data/hw5_spam_dist/spam_data.mat\"\n",
    "\n",
    "spam_data = ut.load_data(SPAM_PATH,BASE_DIR,'training_data')\n",
    "spam_labels = ut.load_data(SPAM_PATH,BASE_DIR,'training_labels').T\n",
    "spam_test = ut.load_data(SPAM_PATH,BASE_DIR,'test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "spamdata, spamlabels = ut.shuffle_data(spam_data,spam_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate\n",
    "spamtraindata,spamvaldata = ut.val_partition(spamdata,valfrac)\n",
    "spamtrainlabels,spamvallabels = ut.val_partition(spamlabels,valfrac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create and train a decision tree classifier using the spam data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_DTclassifier = dt.DecisionTree(treedepth = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_DTclassifier.train(spamtraindata,spamtrainlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the validation accuracy using the trained decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spamDTpredictions = spam_DTclassifier.predict(spamvaldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy = 78.945%\n"
     ]
    }
   ],
   "source": [
    "count,total = 0,0\n",
    "for i in range(len(spamDTpredictions)):\n",
    "    if spamDTpredictions[i] == spamvallabels[i]:\n",
    "        count += 1\n",
    "    total += 1\n",
    "    \n",
    "print('Validation Accuracy = %.3f%%'%(100*count/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make decision tree predictions for the test data, and save to a csv file for upload to Kaggle (0-indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spamDTpredictions = spam_DTclassifier.predict(spam_test)\n",
    "ids = np.arange(len(spamDTpredictions))\n",
    "spamDTpredictions_csv = np.concatenate(([ids],[spamDTpredictions]),axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(BASE_DIR+'spam_DT_testpredictions.csv',spamDTpredictions_csv,fmt='%i',delimiter=',',header='Id,Category',comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Census\n",
    "---------------------------\n",
    "Calculate decision tree and random forest training/validation accuracies for the census dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing (preprocessed) data, shuffling, and separating into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "CENSDAT_PATH = \"Data/census_traindata_vec.csv\"\n",
    "CENSLBL_PATH = \"Data/census_traindata_lbl.csv\"\n",
    "\n",
    "census_data = np.genfromtxt(BASE_DIR+CENSDAT_PATH,delimiter=',')\n",
    "census_labels = np.genfromtxt(BASE_DIR+CENSLBL_PATH,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "census_labels = np.reshape(census_labels,(len(census_labels),1))\n",
    "censusdata, censuslabels = ut.shuffle_data(census_data,census_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate\n",
    "censustraindata,censusvaldata = ut.val_partition(censusdata,valfrac)\n",
    "censustrainlabels,censusvallabels = ut.val_partition(censuslabels,valfrac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create and train a decision tree classifier using the census data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "census_DTclassifier = dt.DecisionTree(treedepth = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "census_DTclassifier.train(censustraindata,censustrainlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the validation accuracy using the trained decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "censuspredictions = census_DTclassifier.predict(censusvaldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "censusvalAcc = ut.val_accuracy(censuspredictions,censusvallabels)\n",
    "    \n",
    "print('Validation Accuracy = %.3f%%'%(100*censusvalAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for the test data, and save to a csv file for upload to Kaggle (1-indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "censusDTpredictions = census_DTclassifier.predict(census_test)\n",
    "ids = np.arange(1,len(censusDTpredictions)+1)\n",
    "censuspredictions_csv = np.concatenate(([ids],[censusDTpredictions]),axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(BASE_DIR+'spam_testpredictions.csv',spampredictions_csv,fmt='%i',delimiter=',',header='Id,Category',comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
