{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load modules to be used in the execution of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import HW03_utils as ut\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_images(image_vectors):\n",
    "# Function to normalize pixel contrast of images\n",
    "\n",
    "        magnitudes = np.linalg.norm(image_vectors,axis=1)\n",
    "        normalized_ims = image_vectors/magnitudes[:,None]\n",
    "        return normalized_ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_bounds(classid,labels):\n",
    "# Function to extract index bounds of the specified class from the dataset\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == classid:\n",
    "            startindex = i\n",
    "            break\n",
    "    stopindex = len(labels)\n",
    "    for i in range(i,len(labels)):\n",
    "        if labels[i] != classid:\n",
    "            stopindex = i\n",
    "            break\n",
    "    \n",
    "    return startindex,stopindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_from_data(classid,data,labels):\n",
    "# Find the start (inclusive) and end (exclusive) of a class within the data, then separate and return the class\n",
    "\n",
    "    startindex,stopindex = get_class_bounds(classid,labels)\n",
    "    \n",
    "    # Separate the specified class\n",
    "    class_data = data[startindex:stopindex]\n",
    "            \n",
    "    return class_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_of_class(classid,data,labels):\n",
    "# Calculate the mean value when the class is fit to a normal distribution\n",
    "    \n",
    "    class_data = get_class_from_data(classid,data,labels)   \n",
    "    # Calculate the mean of the class data\n",
    "    class_mu = np.mean(class_data,axis=0)\n",
    "    \n",
    "    return class_mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cov_of_class(classid,data,labels):\n",
    "# Calcualte the covariance matrix when the class is fit to a normal distribution\n",
    "\n",
    "    class_data = get_class_from_data(classid,data,labels)\n",
    "    # Calculate the covariance matrix from the class data\n",
    "    class_Sigma = np.cov(class_data,rowvar=False)\n",
    "    \n",
    "    return class_Sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_SigmaHat(data,labels,muCs):\n",
    "# Function to calculate the average covariance matrix for the distribution (1 covariance matrix for LDA)\n",
    "\n",
    "    SigmaHat = np.zeros((len(data[0]),len(data[0])))\n",
    "    for i in range(len(data)):\n",
    "        Xi_minus_muC = data[i] - muCs[labels[i]]\n",
    "        SigmaHat += np.outer(Xi_minus_muC,Xi_minus_muC)\n",
    "    \n",
    "    SigmaHat = SigmaHat/len(labels)\n",
    "    \n",
    "    return SigmaHat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_rows(sym_matrix):\n",
    "# Take a symmetric matrix and find rows/columns that are empty\n",
    "\n",
    "    zero_rows = []\n",
    "    for i in range(len(sym_matrix)):\n",
    "        if not np.any(sym_matrix[i]):\n",
    "            zero_rows.append(i)\n",
    "        \n",
    "    return zero_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeInvertible(sym_matrix):\n",
    "# Take a symmetric non-invertible matrix, and eliminate rows/columns to make it invertible\n",
    "    \n",
    "    ZR = zero_rows(sym_matrix)\n",
    "    newlen = len(sym_matrix)-len(ZR)\n",
    "    invmatrix = np.empty((newlen,newlen))\n",
    "    I = 0\n",
    "    for i in range(len(sym_matrix)):\n",
    "        if i in ZR:\n",
    "            continue\n",
    "        J = 0\n",
    "        for j in range(len(sym_matrix)):\n",
    "            if j in ZR:\n",
    "                continue\n",
    "            invmatrix[I,J] = sym_matrix[i,j]\n",
    "            J += 1\n",
    "        I += 1\n",
    "            \n",
    "    return invmatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeZeroVariance(cov_matrix,valdata):\n",
    "# Remove variables with zero variance in the covariance matrix from the validation data set\n",
    "#      -valdata is a nxd array with n rows of samples and d-variables per sample\n",
    "#      -Cov_matrix is a dxd matrix giving the covariances of the d-variables\n",
    "\n",
    "    ZR = zero_rows(cov_matrix)\n",
    "    # Create a new array with validation data corresponding to variables in training set with non-zero variance\n",
    "    NZV_data = np.empty((len(valdata),len(valdata[0])-len(ZR)))\n",
    "    columnI = 0\n",
    "    for columni in range(len(valdata[0])):\n",
    "        if columni in ZR:\n",
    "            continue\n",
    "        NZV_data[:,columnI] = valdata[:,columni]\n",
    "        columnI += 1\n",
    "    \n",
    "    return NZV_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MuAndPi(train_labels,muCs,cov_matrix,ZR):\n",
    "    mu_i = []\n",
    "    pi_i = []\n",
    "    for i in range(10):\n",
    "        # Calculate the mean (without zero variance variables)\n",
    "        mu_i.append(np.zeros(np.shape(cov_matrix)[0]))\n",
    "        J = 0\n",
    "        for j in range(np.shape(muCs[i])[0]):\n",
    "            if j in ZR:\n",
    "                continue\n",
    "            mu_i[i][J] = muCs[i][j]\n",
    "            J += 1\n",
    "        \n",
    "        # Calculate the prior probability\n",
    "        startindex,stopindex = get_class_bounds(i,train_labels)\n",
    "        nPoints = stopindex-startindex\n",
    "        pi_i.append(nPoints/np.shape(train_labels)[0])\n",
    "        \n",
    "    return mu_i,pi_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LDF_solve(X,mu_C,Sigma,pi_C=0.1):\n",
    "# Function to solve the linear discriminant function for class C (will compute LDF for 1 variable but for all data points)\n",
    "    \n",
    "    LDFs_C = np.zeros(len(X))\n",
    "    muCinvSigma = np.dot(mu_C,np.linalg.inv(Sigma))\n",
    "    muCinvSigmamuC = np.dot(muCinvSigma,mu_C)\n",
    "    logpiC = math.log(pi_C)\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        LDFs_C[i] = np.dot(muCinvSigma,x) - 0.5*muCinvSigmamuC + logpiC\n",
    "    \n",
    "    return LDFs_C\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maximize_LDFs(valdata,mu_i,cov_matrix,pi_i):\n",
    "    lin_disc_fns = np.empty((len(valdata),10))\n",
    "    for i in range(10):\n",
    "        print('Calculating LDFs for digit ',i)\n",
    "        mu_C = mu_i[i]\n",
    "        pi_C = pi_i[i]\n",
    "        lin_disc_fns[:,i] = LDF_solve(valdata,mu_C,cov_matrix,pi_C)\n",
    "    max_LDF_indices = np.empty(len(valdata))\n",
    "    for i in range(len(valdata)):\n",
    "        max_LDF_indices[i] = np.argmax(lin_disc_fns[i])\n",
    "    \n",
    "    return max_LDF_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CS_DIR = r\"/Users/mitch/Documents/Cal/2 - 2017 Spring/COMPSCI 289A - Intro to Machine Learning/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "data_array = ut.loaddata(\"hw3_mnist_dist/hw3_mnist_dist/train.mat\",CS_DIR+r\"HW03/Data\",\"trainX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle data and set aside validation set\n",
    "np.random.shuffle(data_array)\n",
    "\n",
    "trainarray = data_array[:-10000]\n",
    "valarray = data_array[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(traindata,trainlabels,valdata,vallabels):\n",
    "# Main block of code\n",
    "    \n",
    "    # Create a list of the means for each class\n",
    "    muCs = np.empty((10,len(traindata[0])))\n",
    "    for i in range(10):\n",
    "        muCs[i] = mean_of_class(i,traindata,trainlabels)\n",
    "\n",
    "    SigmaHat = calc_SigmaHat(traindata,trainlabels,muCs)\n",
    "\n",
    "    newcov = makeInvertible(SigmaHat)\n",
    "    newvaldata = removeZeroVariance(SigmaHat,valdata)\n",
    "\n",
    "    ZR = zero_rows(SigmaHat)\n",
    "\n",
    "    mu_i,pi_i = MuAndPi(trainlabels,muCs,newcov,ZR)\n",
    "\n",
    "    digitPicks = maximize_LDFs(newvaldata,mu_i,newcov,pi_i)\n",
    "    count, total = 0,0\n",
    "    for i in range(len(digitPicks)):\n",
    "        if digitPicks[i] == vallabels[i]:\n",
    "            count += 1\n",
    "        total += 1\n",
    "        \n",
    "    # VERBOSE COMMANDS FOR WATCHING PROGRESS [OPTIONAL]\n",
    "    #    if total%200 == 0:\n",
    "    #        print(total,'points evaluated; current score =',count/total)\n",
    "    \n",
    "    print('Final Score: ',count/total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organize array by digit\n",
    "trainarray_byclass = trainarray[trainarray[:,-1].argsort()]\n",
    "valarray_byclass = valarray[valarray[:,-1].argsort()]\n",
    "\n",
    "train_data = trainarray_byclass[:,:-1]\n",
    "train_labels = trainarray_byclass[:,-1]\n",
    "\n",
    "val_data = valarray_byclass[:,:-1]\n",
    "val_labels = valarray_byclass[:,-1]\n",
    "\n",
    "normalized_traindata = normalize_images(train_data)\n",
    "normalized_valdata = normalize_images(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.0805\n",
      "200 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.1036\n",
      "500 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.0957\n",
      "1000 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.1056\n",
      "2000 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.6587\n",
      "5000 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.8382\n",
      "10000 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.1067\n",
      "30000 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.8692\n",
      "50000 training samples: \n",
      "Calculating LDFs for digit  0\n",
      "Calculating LDFs for digit  1\n",
      "Calculating LDFs for digit  2\n",
      "Calculating LDFs for digit  3\n",
      "Calculating LDFs for digit  4\n",
      "Calculating LDFs for digit  5\n",
      "Calculating LDFs for digit  6\n",
      "Calculating LDFs for digit  7\n",
      "Calculating LDFs for digit  8\n",
      "Calculating LDFs for digit  9\n",
      "Final Score:  0.8688\n"
     ]
    }
   ],
   "source": [
    "# Train on subsets of full training data set\n",
    "for number in [100,200,500,1000,2000,5000,10000,30000,50000]:\n",
    "    trainarraysubset = trainarray[:number]\n",
    "    \n",
    "    # Organize array by digit\n",
    "    trainarray_byclass = trainarraysubset[trainarraysubset[:,-1].argsort()]\n",
    "    valarray_byclass = valarray[valarray[:,-1].argsort()]\n",
    "    \n",
    "    # Separate data and labels\n",
    "    train_data = trainarray_byclass[:,:-1]\n",
    "    train_labels = trainarray_byclass[:,-1]\n",
    "    val_data = valarray_byclass[:,:-1]\n",
    "    val_labels = valarray_byclass[:,-1]\n",
    "    \n",
    "    # Normalize training and validation data\n",
    "    normalized_train_data = normalize_images(train_data)\n",
    "    normalized_val_data = normalize_images(val_data)\n",
    "    \n",
    "    print(number,\"training samples: \")\n",
    "    main(normalized_train_data,train_labels,normalized_val_data,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
